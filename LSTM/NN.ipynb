{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Activation, Dense, Dropout, Embedding, LSTM, Bidirectional, Permute, Input, Lambda, RepeatVector, Multiply, Flatten\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Embedding\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras import optimizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hypers\n",
    "MAX_NB_WORDS = 20000\n",
    "MAX_SEQUENCE_LENGTH = 60\n",
    "LSTM_SIZE = 300\n",
    "DROP_RATE = 0.3\n",
    "L_RATE = 1e-3\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCH = 4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv( \"./olid-training-v1.0.tsv\", sep=\"\\t\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13240, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                                       86426\n",
       "tweet        @USER She should ask a few native Americans wh...\n",
       "subtask_a                                                  OFF\n",
       "subtask_b                                                  UNT\n",
       "subtask_c                                                  NaN\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.loc[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_a = pd.read_csv( \"./testset_a.tsv\", sep=\"\\t\" )\n",
    "df_test_b = pd.read_csv( \"./testset_b.tsv\", sep=\"\\t\" )\n",
    "df_test_c = pd.read_csv( \"./testset_c.tsv\", sep=\"\\t\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                                   15923\n",
       "tweet    #WhoIsQ #WheresTheServer #DumpNike #DECLASFISA...\n",
       "label                                                  OFF\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_a.loc[0 ,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(860, 3), (240, 3), (213, 3)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ a.shape for a in [ df_test_a, df_test_b, df_test_c ] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOVE_DIR = \"/nfs/nas-7.1/cflin/glove.6B/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df_train[\"tweet\"].tolist() + df_test_a['tweet'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14100"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_len = [ len( w.split() ) for w in texts ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "word_index = tokenizer.word_index\n",
    "# data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_padded_seq(sentence):\n",
    "        return pad_sequences( tokenizer.texts_to_sequences([sentence]), maxlen=MAX_SEQUENCE_LENGTH )[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['seq'] = df_train['tweet'].map( lambda x: sentence_to_padded_seq(x) )\n",
    "df_test_a['seq'] = df_test_a['tweet'].map( lambda x: sentence_to_padded_seq(x) )\n",
    "df_test_b['seq'] = df_test_b['tweet'].map( lambda x: sentence_to_padded_seq(x) )\n",
    "df_test_c['seq'] = df_test_c['tweet'].map( lambda x: sentence_to_padded_seq(x) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train['seq'][0], df_train['tweet'][0]\n",
    "# df_train['seq'].tolist()\n",
    "\n",
    "idx_task_b = df_train.loc[ df_train['subtask_b'].notna(), : ].index\n",
    "idx_task_c = df_train.loc[ df_train['subtask_c'].notna(), : ].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train['subtask_a']\n",
    "y_train = [ 0 if w == \"NOT\" else 1 for w in y_train]\n",
    "# print( Counter(y_train) )\n",
    "y_train = to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_b = df_train['subtask_b'][idx_task_b]\n",
    "y_train_b = [ 0 if w == \"UNT\" else 1 for w in y_train_b]\n",
    "# print( Counter(y_train) )\n",
    "y_train_b = to_categorical(y_train_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 2407, 1: 1074, 2: 395})\n"
     ]
    }
   ],
   "source": [
    "y_train_c = df_train['subtask_c'][idx_task_c]\n",
    "# y_train_b = [ 0 if w == \"UNT\" else 1 for w in y_train_b]\n",
    "\n",
    "ls_tmp = []\n",
    "for w in y_train_c:\n",
    "    if w == \"IND\":\n",
    "        ls_tmp.append( 0 )\n",
    "    elif w == \"GRP\":\n",
    "        ls_tmp.append( 1 )\n",
    "    else:\n",
    "        ls_tmp.append( 2 )\n",
    "y_train_c = ls_tmp\n",
    "print( Counter( y_train_c ) )\n",
    "\n",
    "y_train_c = to_categorical(y_train_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4400, 2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'UNT': 524, 'TIN': 3876, nan: 8840})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter( df_train['subtask_b'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'OTH': 35, 'GRP': 78, 'IND': 100})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(df_test_c['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_a = df_test_a['label']\n",
    "y_test_a = [ 0 if w == \"NOT\" else 1 for w in y_test_a]\n",
    "y_test_a = to_categorical(y_test_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 213, 0: 27})\n"
     ]
    }
   ],
   "source": [
    "y_test_b = df_test_b['label']\n",
    "y_test_b = [ 0 if w == \"UNT\" else 1 for w in y_test_b]\n",
    "print( Counter( y_test_b ) )\n",
    "y_test_b = to_categorical(y_test_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 100, 1: 78, 2: 35})\n"
     ]
    }
   ],
   "source": [
    "y_test_c = df_test_c['label']\n",
    "ls_tmp = []\n",
    "for w in y_test_c:\n",
    "    if w == \"IND\":\n",
    "        ls_tmp.append( 0 )\n",
    "    elif w == \"GRP\":\n",
    "        ls_tmp.append( 1 )\n",
    "    else:\n",
    "        ls_tmp.append( 2 )\n",
    "y_test_c = ls_tmp\n",
    "print( Counter( y_test_c ) )\n",
    "y_test_c = to_categorical(y_test_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "with open(os.path.join(GLOVE_DIR, 'glove.6B.300d.txt' ), encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        \n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(word_index) + 1, 300))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "inputs = Input( shape=(MAX_SEQUENCE_LENGTH,) )\n",
    "\n",
    "m = Embedding(len(word_index) + 1,\n",
    "                            300,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False,\n",
    "                            name=\"embedding_layer\")(inputs)\n",
    "\n",
    "m = Bidirectional(LSTM(LSTM_SIZE, return_sequences=False), name=\"biLSTM\")(m)\n",
    "# m = Dropout(DROP_RATE)(m)\n",
    "# output = Dense(2, activation='softmax')(m) # subtask a&b\n",
    "output = Dense(3, activation='softmax')(m) # subtask c\n",
    "model = Model(input=inputs, output=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = optimizers.Adam(lr=L_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(adam, 'binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4400, 6)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.loc[ idx_task_b, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'UNT': 524, 'TIN': 3876, nan: 8840})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter( df_train['subtask_b'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(df_train['seq'].tolist())\n",
    "X_train_b = X_train[ idx_task_b ]\n",
    "X_train_c = X_train[ idx_task_c ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13240, 4400, 3876)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(X_train_b), len(X_train_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "3876/3876 [==============================] - 5s 1ms/step - loss: 0.4712 - acc: 0.7842\n",
      "Epoch 2/4\n",
      "3876/3876 [==============================] - 4s 1ms/step - loss: 0.4299 - acc: 0.8108\n",
      "Epoch 3/4\n",
      "3876/3876 [==============================] - 4s 1ms/step - loss: 0.4018 - acc: 0.8240\n",
      "Epoch 4/4\n",
      "3876/3876 [==============================] - 4s 1ms/step - loss: 0.3826 - acc: 0.8315\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7feb381c9908>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_c, y_train_c,\n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=NUM_EPOCH,\n",
    "#           validation_data=[x_val, y_val]\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict( np.array( df_test_c['seq'].tolist() ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(213, 3)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_max = np.argmax( pred, axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(213,)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_max.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48148148148148145"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "\n",
    "f1_score(y_true= np.argmax(y_test_c, axis=1), y_pred=pred_max, average='macro')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
