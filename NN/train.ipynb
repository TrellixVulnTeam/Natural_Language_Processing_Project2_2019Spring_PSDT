{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "import sys\n",
    "import ast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchvision import transforms, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class itemDataset(Dataset):\n",
    "    def __init__(self,file_name,mode='train',transform=None):\n",
    "        self.mode = mode\n",
    "        self.data = []\n",
    "        \n",
    "        temp = pd.read_csv(file_name)\n",
    "        if(mode=='test'):\n",
    "            for query,length in zip(temp['query'],temp['length']):\n",
    "                query = ast.literal_eval(query)\n",
    "                length = ast.literal_eval(length)\n",
    "\n",
    "                self.data.append({\n",
    "                    'query':query,\n",
    "                    'length':length\n",
    "                })\n",
    "                \n",
    "        elif(mode=='train' or mode=='eval'):\n",
    "            for query,length,label in zip(temp['query'],temp['length'],temp['label']):\n",
    "                query = ast.literal_eval(query)\n",
    "                length = ast.literal_eval(length)\n",
    "\n",
    "                if(label=='disagreed'):\n",
    "                    t1,t2 = [0.0,1.0],[0.0,1.0]\n",
    "                    l = 2\n",
    "                elif(label=='agreed'):\n",
    "                    t1,t2 = [0.0,1.0],[1.0,0.0]\n",
    "                    l = 1\n",
    "                elif(label=='unrelated'):\n",
    "                    t1,t2 = [1.0,0.0],[0.0,0.0]\n",
    "                    l = 0\n",
    "\n",
    "                self.data.append({\n",
    "                    'query1':query[0],\n",
    "                    'length1':length[0],\n",
    "                    'query2':query[1],\n",
    "                    'length2':length[1],\n",
    "                    'label_relation':t1,\n",
    "                    'label_type':t2,\n",
    "                    'label':l\n",
    "                })\n",
    "                \n",
    "                \n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        if(transforms):\n",
    "            sample = self.transform(self.data[idx])\n",
    "        return sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    def __call__(self,sample):\n",
    "        #print(sample)\n",
    "        for name in ['query1','length1','query2','length2','label']:\n",
    "            sample[name] = torch.tensor(sample[name],dtype=torch.long)\n",
    "\n",
    "        for name in ['label_relation','label_type']:\n",
    "            if(name in sample):\n",
    "                sample[name] = torch.tensor(sample[name],dtype=torch.float)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    output = dict()\n",
    "\n",
    "    for name in ['length1','length2','label_relation','label_type','label']:\n",
    "        temp = [ _[name] for _ in data]\t \n",
    "        output[name] = torch.stack(temp, dim=0) \n",
    "\n",
    "\n",
    "    #deal with source and target\n",
    "    for name in range(1,3):\n",
    "        length = output['length{0}'.format(name)]\n",
    "        name = 'query{0}'.format(name)\n",
    "        l = length.max().item()\n",
    "\n",
    "        for i in range(len(data)):\n",
    "            if(l-length[i].item()>0):\n",
    "                data[i][name] =  torch.cat([data[i][name],torch.zeros(l-length[i].item(),dtype=torch.long)],dim=-1)\n",
    "\n",
    "        temp = [ _[name] for _ in data]\n",
    "        output[name] = torch.stack(temp, dim=0).long()\n",
    "\n",
    "    return {\n",
    "        'length':[output['length1'],output['length2']],\n",
    "        'query':[output['query1'],output['query2']],\n",
    "        'label_relation':output['label_relation'],\n",
    "        'label_type':output['label_type'],\n",
    "        'label':output['label']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "args = Args()\n",
    "\n",
    "args.batch_size=32\n",
    "args.dropout=0\n",
    "args.epoch=200\n",
    "args.gpu=0\n",
    "args.embeds_dim=128\n",
    "args.hidden_dim=128\n",
    "args.num_layer=2\n",
    "args.learning_rate=0.0001\n",
    "args.model=True\n",
    "args.print_freq=1\n",
    "args.save=True\n",
    "args.input_size=49527\n",
    "args.batch_first=True\n",
    "args.data='./data/all_no_embedding/'\n",
    "args.mode = 'train'\n",
    "args.batch_first = True\n",
    "args.step = 1\n",
    "args.model = 'siamese'\n",
    "\n",
    "with open('{0}/vocab'.format(args.data)) as f:\n",
    "    args.word_num = len(f.readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Base(nn.Module):\n",
    "    def __init__(self,args):\n",
    "        super(Base, self).__init__()\n",
    "        self.args = args\n",
    "\n",
    "        self.word_emb =nn.Embedding(args.word_num,args.embeds_dim)\n",
    "\n",
    "        if(args.mode == 'pretrain'):\n",
    "            self.load()\n",
    "            self.word_emb.weight.requires_grad = False\n",
    "            print(\"here\",self.word_emb.weight.requires_grad)\n",
    "\n",
    "    def load(self):\n",
    "        if(self.args.embed_type == 'glove'):\n",
    "            pass\n",
    "        elif(self.args.embed_type == 'fasttext'):\n",
    "            \n",
    "            with open('./data/embedding/glove.6B.100d.txt') as f:\n",
    "                arr = np.zeros((self.word_emb.weight.shape[0],self.word_emb.weight.shape[1]),dtype=np.float32)\n",
    "                for i,line in enumerate(f):\n",
    "                    for j,num in enumerate(line.strip().split()[1:]):\n",
    "                        arr[i+1,j] = float(num)\n",
    "                        \n",
    "                self.word_emb.weight = nn.Parameter(torch.tensor(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class siamese(Base):\n",
    "    def __init__(self, args):\n",
    "        super(siamese, self).__init__(args)\n",
    "        \n",
    "        self.embeds_dim = args.embeds_dim\n",
    "        self.hidden_dim = args.hidden_dim\n",
    "        self.num_layer = args.num_layer\n",
    "        self.batch_first = args.batch_first\n",
    "        \n",
    "        self.ln_embeds = nn.LayerNorm(args.embeds_dim)\n",
    "        self.rnn = nn.LSTM(self.embeds_dim, self.hidden_dim, batch_first=self.batch_first , bidirectional=True, num_layers=self.num_layer)\n",
    "\n",
    "\n",
    "        self.linear1 = nn.Linear(4*self.hidden_dim,self.hidden_dim)\n",
    "        self.linear2_1 = nn.Linear(self.hidden_dim,2)\n",
    "        self.linear2_2 = nn.Linear(self.hidden_dim,2)\n",
    "\n",
    "    def forward(self, querys,lengths):\n",
    "        def pack(seq,seq_length):\n",
    "            sorted_seq_lengths, indices = torch.sort(seq_length, descending=True)\n",
    "            _, desorted_indices = torch.sort(indices, descending=False)\n",
    "\n",
    "            if self.batch_first:\n",
    "                seq = seq[indices]\n",
    "            else:\n",
    "                seq = seq[:, indices]\n",
    "            packed_inputs = nn.utils.rnn.pack_padded_sequence(seq,\n",
    "                                                            sorted_seq_lengths.cpu().numpy(),\n",
    "                                                            batch_first=self.batch_first)\n",
    "\n",
    "            return packed_inputs,desorted_indices\n",
    "\n",
    "        def unpack(res, state,desorted_indices):\n",
    "            padded_res,_ = nn.utils.rnn.pad_packed_sequence(res, batch_first=self.batch_first)\n",
    "\n",
    "            state = [state[i][:,desorted_indices] for i in range(len(state)) ] \n",
    "\n",
    "            if(self.batch_first):\n",
    "                desorted_res = padded_res[desorted_indices]\n",
    "            else:\n",
    "                desorted_res = padded_res[:, desorted_indices]\n",
    "\n",
    "            return desorted_res,state\n",
    "\n",
    "        def feat_extract(output,length,mask):\n",
    "            \"\"\"\n",
    "            answer_output: batch*sentence*feat_len\n",
    "            query_output:  batch*sentence*feat_len\n",
    "            for simple rnn, we just take the output from \n",
    "            \"\"\"\n",
    "            if( self.batch_first == False ):\n",
    "                output = output.transpose(0,1) \n",
    "\n",
    "            output = [torch.cat([ output[i][ length[i]-1 ][:self.hidden_dim] , \n",
    "                                        output[i][0][self.hidden_dim:]] , dim=-1 ) for i in range(length.shape[0])]\n",
    "            output = torch.stack(output,dim=0)\n",
    "\n",
    "            return output\n",
    "\n",
    "        query_embs = [self.word_emb(querys[0]),self.word_emb(querys[1])]\n",
    "        masks = [querys[0].eq(0),querys[1].eq(0)]\n",
    "\n",
    "        query_result = []\n",
    "        for query_emb,length,mask in zip(query_embs,lengths,masks):\n",
    "            packed_inputs,desorted_indices = pack(query_emb,length)\n",
    "            res, state = self.rnn(packed_inputs)\n",
    "            query_res,_ = unpack(res, state,desorted_indices)\n",
    "            query_result.append(feat_extract(query_res,length.int(),mask))\n",
    "        \n",
    "        query_result = torch.cat([query_result[0],query_result[1]],dim=1)\n",
    "        \n",
    "        out = self.linear1(query_result)\n",
    "        \n",
    "        out_1 = self.linear2_1(F.relu(out))\n",
    "        out_2 = self.linear2_2(F.relu(out))\n",
    "        return [out_1,out_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(train_file,eval_file,batch_size):\n",
    "    train_dataset = itemDataset( file_name=train_file,mode='train',transform=transforms.Compose([ToTensor()]))\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, num_workers=16,collate_fn=collate_fn)\n",
    "    \n",
    "    eval_dataset = itemDataset( file_name=eval_file,mode='eval',transform=transforms.Compose([ToTensor()]))\n",
    "    eval_dataloader = DataLoader(eval_dataset, batch_size=batch_size,shuffle=True, num_workers=16,collate_fn=collate_fn)\n",
    "    \n",
    "    return {\n",
    "        'train':train_dataloader,\n",
    "        'eval':eval_dataloader\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./data/all_no_embedding/train.csv'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.path.join('./data/all_no_embedding/','train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check device\n",
      "the device is in cuda\n",
      "loading data\n",
      "setting model\n",
      "siamese(\n",
      "  (word_emb): Embedding(6261, 128)\n",
      "  (ln_embeds): LayerNorm(torch.Size([128]), eps=1e-05, elementwise_affine=True)\n",
      "  (rnn): LSTM(128, 128, num_layers=2, batch_first=True, bidirectional=True)\n",
      "  (linear1): Linear(in_features=512, out_features=128, bias=True)\n",
      "  (linear2_1): Linear(in_features=128, out_features=2, bias=True)\n",
      "  (linear2_2): Linear(in_features=128, out_features=2, bias=True)\n",
      ")\n",
      "start training\n"
     ]
    }
   ],
   "source": [
    "print(\"check device\")\n",
    "if(torch.cuda.is_available() and args.gpu>=0):\n",
    "    device = torch.device('cuda')\n",
    "    print('the device is in cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('the device is in cpu')\n",
    "\n",
    "print(\"loading data\")\n",
    "dataloader = get_data('./data/all_no_embedding/train.csv','./data/all_no_embedding/eval.csv',args.batch_size)\n",
    "\n",
    "print(\"setting model\")\n",
    "if(args.model=='siamese'):\n",
    "    model = siamese(args)\n",
    "model = model.to(device=device)\n",
    "\n",
    "print(model)\n",
    "optimizer = optim.Adam(model.parameters(),lr=args.learning_rate)\n",
    "criterion = nn.KLDivLoss()\n",
    "\n",
    "loss_best = 100000000\n",
    "print(\"start training\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,data,criterion,step):\n",
    "    total={'loss_relation':0,'loss_type':0,'count':0,'num':0}\n",
    "    for i,data in enumerate(data):\n",
    "        data = convert(data,device)\n",
    "\n",
    "        #deal with the classfication part\n",
    "        out = model(data['query'],data['length'])\n",
    "        \n",
    "        loss = criterion(F.log_softmax(out[0],dim=1),data['label_relation']) \n",
    "        loss.backward(retain_graph=True)\n",
    "        total['loss_relation'] += loss.cpu().detach()\n",
    "        \n",
    "        loss = criterion(F.log_softmax(out[1],dim=1),data['label_type']) \n",
    "        loss.backward(retain_graph=True)\n",
    "        total['loss_type'] += loss.cpu().detach()\n",
    "        total['num'] += out[0].shape[0]\n",
    "        \n",
    "        total['count'] += ((out[0].topk(1)[1]*(1+out[1].topk(1)[1])).view(-1) == data['label']).sum()\n",
    "        \n",
    "        if(i%1==0):\n",
    "            optimizer.step()\n",
    "            model.zero_grad()\n",
    "\n",
    "        if(i%160==0):\n",
    "            print(i,' train loss(relation):{0} loss(type):{1} acc:{2}/{3}'.format(total['loss_relation'],total['loss_type'],total['count'],total['num']))\n",
    "            total={'loss_relation':0,'loss_type':0,'count':0,'num':0}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model,data,criterion,loss_best):\n",
    "    total={'loss':0,'count':0,'num':0}\n",
    "    for i,data in enumerate(data):\n",
    "        with torch.no_grad():\n",
    "            #\n",
    "            data = convert(data,device)\n",
    "            out = model(data['query'],data['length'])\n",
    "\n",
    "            loss = criterion(F.log_softmax(out[0],dim=1),data['label_relation']) \n",
    "            total['loss_relation'] += loss.cpu().detach()\n",
    "\n",
    "            loss = criterion(F.log_softmax(out[1],dim=1),data['label_type'])\n",
    "            total['loss_type'] += loss.cpu().detach()\n",
    "            total['num'] += out[0].shape[0]\n",
    "\n",
    "            total['count'] += out[0].topk(1)[1]*(1+out[1].topk(1)[1]) == data['label']\n",
    "        \n",
    "    print(i,' test loss(relation):{0} loss(type):{1} acc:{2}/{3}'.format(total['loss_relation'],total['loss_type'],total['count'],total['num']))\n",
    "    \n",
    "    check = {\n",
    "            'args':args,\n",
    "            'model':model.state_dict()\n",
    "            }\n",
    "    torch.save(check, './saved_models/{0}/step_{1}.pkl'.format(args.save,now))\n",
    "\n",
    "    if(Loss['loss']<loss_best):\n",
    "        torch.save(check, './saved_models/{0}/best.pkl'.format(args.save))\n",
    "        loss_best = Loss['class']\n",
    "    \n",
    "    return loss_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(data,device):\n",
    "    for name in data:\n",
    "        if(type(data[name])==list):\n",
    "            for i in range(len(data[name])):\n",
    "                data[name][i] = data[name][i].to(device)\n",
    "        else:\n",
    "            data[name] = data[name].to(device)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  train loss(relation):0.35605740547180176 loss(type):0.12137935310602188 acc:2/32\n",
      "160  train loss(relation):51.64070129394531 loss(type):10.66838264465332 acc:3192/5120\n",
      "320  train loss(relation):46.73356628417969 loss(type):6.126214981079102 acc:3526/5120\n",
      "480  train loss(relation):44.73812484741211 loss(type):2.2638931274414062 acc:3549/5120\n",
      "640  train loss(relation):44.338260650634766 loss(type):0.8784410357475281 acc:3570/5120\n",
      "800  train loss(relation):44.18479919433594 loss(type):0.6398261189460754 acc:3556/5120\n",
      "960  train loss(relation):43.49910354614258 loss(type):0.515021800994873 acc:3593/5120\n",
      "1120  train loss(relation):43.50716781616211 loss(type):0.6514284610748291 acc:3593/5120\n",
      "1280  train loss(relation):42.54240036010742 loss(type):0.41000688076019287 acc:3609/5120\n"
     ]
    }
   ],
   "source": [
    "model.zero_grad()\n",
    "\n",
    "model.train()\n",
    "train(model,dataloader['train'],criterion,args.step)\n",
    "model.eval()\n",
    "loss_best = eval(model,dataloader['eval'],criterion,loss_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
